---
layout: post
title: 记一次深度学习数据传输及训练的性能优化
author: DuckSoft
categories: [深度学习]
tags: [GPU, CUDA, 机器学习, 人工智能, 深度学习, Linux, 性能优化, 生物医学, UNet]
image: cutting.jpg
---

## 开端
某校（具体学校隐去）生物信息医学工程博士生（下称博士）重金邀请，让我辅助他进行针对 LUNA 肺癌数据集的结节 3D 分割模型的构建。说是重金，其实给的报酬也不是很多，然而盛情难却，加上和这个博士关系不错，还是接了这一手生意。

在邀请我进行辅助之前，博士已在学校的计算节点上耗费将近一星期时间，将所需的训练/测试集的三维图像、标签从 `.mhd/.raw` 文件处理为 `.npy` 格式的 `numpy` 矩阵文件。数据集有了，模型有现成的作参考，博士使用 PyTorch 框架，不到半个小时就无比熟练地搭建出了一个 3D UNet 的模型。简单调试，证明网络没有明显问题后，下面就准备开始进行正式的训练了。

## 海量数据集的困惑
由于用于处理数据的服务器与实际训练的服务器不在同一台上，我们需要对处理过的数据集先进行转移。简单的 `du -hs` 命令发现，区区 3000 张的训练集、测试集的三维灰度图像、二进制标记文件的总大小在 `.npy` 格式下就**已经达到了惊人的 `1TB` 的大小**。博士吃惊之余，还是随手打开了 WinSCP，开始把文件从训练服务器向测试服务器拷贝。

博士点燃一根烟起身离开，我抿了一口保温杯里的水，盯着屏幕上 `100MB/s` 的“神速”不禁陷入了沉思。照这个速度下去，`1024 GB × 1024 GB/MB ÷ 100 MB/s ÷ 3600s/h`，要拷完这些数据集得花上三个小时左右。有没有什么办法能加速这个过程呢？

## 压缩与围观
我的第一想法就是压缩。因为在实际进行深度学习的过程中，`.npy` 格式的数据集实属罕见，能见到的比较接近的范例是 `.npz` 格式，也就是经过压缩的 `.npy` 格式。并且在这个肺部的三维的灰度立体图像中，显然数据集本身属于稀疏矩阵，而此时压缩的效果必然非常明显。

说干就干，我不等博士回来，直接把 WinSCP 的拷贝过程停掉，然后登录到了数据预处理的服务器上。这是一台对称双处理器的 32 核心 64 线程的 Intel Xeon 处理器，配有 256 GB 的服务器内存，可谓性能拔群。根据 WinSCP 上指示的路径，我定位到处理后的数据集所在的目录，直接开始 `tar -cvzf ../dataset.tar.gz .`。

屏幕上不断刷出一行一行的数据集文件的完整路径，盯着屏幕我又陷入了思考。调查了一下数据集文件的总数目，然后根据屏幕滚屏的速度，大致估算出了压缩这些数据集所需要的时间——**2个小时**。这显然是不可接受的。问题到底出在哪里呢？

百无聊赖，习惯性地点开了 `htop` 查看系统的负载情况。令人吃惊的是，服务器**只有一个核心在 `100%` 运作**，剩下的所有核心的负载程度都不足 `1%`，孤零零的满载核心非常扎眼。往下扫视，CPU 占用第一的程序便是我们的压缩程序 `tar`。这可当真应了那句主机界的话：**一核有难，六十三核围观**。

## 并行压缩
到了这个地步，不难意识到这样一个问题：传统的 `tar` 压缩程序是单线程执行的，而在我们的服务器上，根本没有充分地利用服务器庞大的算力资源，导致了“线程围观惨案”，也导致了完成时间不可接受。

博士抽完烟回来了，看着我神奇的操作，刚想问我发生了什么就被我示意堵住了嘴巴。我在博士的电脑上打开了 Google，然后搜索 linux parallel compression 这样的关键字。然而刚想按下回车键，我突然想起在 Arch Linux 上安装 docker 的时候的几个可选依赖，其中有一个可选依赖叫做 `pigz`，其中的说明中有相关的字样。

说干就干，在博士的注目下我掏出了随身的笔记本，执行 `pacman -Si pigz`：

```
软件库         : community
名字           : pigz
版本           : 2.4-1
描述           : Parallel implementation of the gzip file compressor
架构           : x86_64
URL            : https://www.zlib.net/pigz
```

其中的描述赫然就写着“并行实现的 gzip 文件压缩器”字样。使用 `man pigz` 命令仔细查阅一番用户手册之后，我使用 `tar -cvf - . | pigz -9 -p 60 > ../dataset.tar.gz` 命令，同时开启 60 个线程进行并行压缩。

回车键甫一按下，屏幕立即就像要爆炸了一般疯狂刷出日志。我停掉进程，然后把他挂在一个 `screen` 会话中继续运行。**不到十分钟**的功夫，当我上去再次检查的时候，发现压缩操作已经完成了，**最终得到了一个只有 `3.9GB` 的单个文件**。

这是几乎令人疯狂的压缩率，接近 `300:1` 的压缩尺寸，使得整个数据集从预处理服务器移动到训练服务器**最终只花费了 40 秒左右的时间**，而解压操作只花费了不到五分钟的时间。操作完成之后，博士整个人都看呆了。他本人表示，原本打算打两盘 Dota 2 打发一下时间来着，**没想到这么快就把数据集传完了**。

